    # -*- coding: utf-8 -*-
"""globalaihubproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qTIedhKyxYviTvwDsYO4Gx2Cjc9OgEsS
"""

import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,CSVLogger
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
from sklearn import metrics
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')

# resme grayscale dönüşümü yapıldı
def imgGrayScale(img_file_path):
    image = cv2.imread(img_file_path)
    grayImage=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
    return grayImage
# resim 128*128 boyutuna getirildi
def ResizeImage(img, size):
    return cv2.resize(img, (size, size))
#resim 255 değerine bölünerek normalize edildi
def NormalizeImage(img):
    return img/255;
#resimler çekilerek re_image listesine [resim,label] biçiminde kayıt edildi
#spectogramın dosya yolu 
spectogram_path="/content/drive/MyDrive/spectrograms/"     
re_image =[]
for path, directories, files in os.walk(spectogram_path):
    for file_name in files:
        if path is not spectogram_path and file_name.endswith('.png'):
            data = cv2.imread(os.path.join(path,file_name), 0)
            grayImage=imgGrayScale(os.path.join(path,file_name))
            resizeImage=ResizeImage(grayImage,128)
            normalizeImage=NormalizeImage(resizeImage)
            label=int(os.path.basename(os.path.normpath(path)))
            re_image.append([normalizeImage,label])
#re_image listesi rastgele karıştırıldı
random.shuffle(re_image)
dataframe=pd.DataFrame(re_image,columns=["image","label"])

#X resimler Y etiketler olacak şekilde ayrıldı
X=np.array(dataframe['image'].tolist())
Y=np.array(dataframe['label'].tolist())

#test ve train setleri oluşturuldu
X_TRAIN, X_VALIDATE, Y_TRAIN, Y_VALIDATE = train_test_split(X,Y, test_size= 0.1)
X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X_TRAIN,Y_TRAIN,test_size = 0.3)

"""Model Egitimi"""

model = tf.keras.models.Sequential([
    #evrisim katmanı
    #32 filtre sayısı 3,3 ise evrisim yapan filtre boyutu
    #aktivasyon fonksiyonu relu input shape her bir resmin boyutu
    tf.keras.layers.Conv2D(64, (3, 3), padding = "same" ,activation='relu', input_shape=(128,128,1)),
    #bu katman kendisine verilen verileri 2*2 sekilde gruplayıp bu gruptaki en buyuk elemanla yeni veri olusturur
    #kendisine verilen resim 2x*2x boyutunda ise bunu x*x yapar
    tf.keras.layers.MaxPooling2D(2, 2),
    #filtre sayısı 128
    tf.keras.layers.Conv2D(128, (3, 3),padding = "same", activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    #filtre sayısı 256
    tf.keras.layers.Conv2D(256, (3, 3), padding = "same",activation='relu'),
    tf.keras.layers.Flatten(),
    #512 nörona sahip bir katman
    tf.keras.layers.Dense(512, activation='relu'),
    #her bir epoch da bir önceki katmandaki nöronların %20 sini rastgele iptal ediyoruz
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

#Modeli detayli sekilde gösterir kac parametre var veya katman cıkıs boyutları gibi bilgiler
model.summary()

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

r = model.fit(X_TRAIN ,Y_TRAIN ,validation_data = (X_TEST, Y_TEST) ,batch_size = 128 ,epochs = 150)

#Modelin test verisi üstündeki başarısı
model.evaluate(X_TEST,Y_TEST)

#Modelin loss değerlerinin zamana göre değişimi
#ilki eğitim verisi için 
#ikinci test verisi için
plt.plot(r.history['loss'],label='loss')
plt.plot(r.history['val_loss'],label='val_loss')
plt.legend()

#Modelin accuracy değerlerinin zamana göre değişimi
#ilki eğitim verisi için 
#ikinci test verisi için
plt.plot(r.history['accuracy'],label='acc')
plt.plot(r.history['val_accuracy'],label='val_acc')
plt.legend()